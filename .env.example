# ============================================================================
# ü§ñ WebCodeTool - Unified Environment Configuration
# ============================================================================
# This file contains ALL configuration for both the web UI and AI agents.
# Copy this file to .env and customize as needed.
# ============================================================================

# ============================================================================
# WEB SERVER CONFIGURATION
# ============================================================================

# Port for web server (default: 3000)
PORT=3000

# Default workspace directory for file editor
# Set this to your preferred project directory
# If not set, defaults to the project root directory
# Examples:
#   WORKSPACE_DIR=/home/user/my-projects
#   WORKSPACE_DIR=/workspace
#   WORKSPACE_DIR=.
WORKSPACE_DIR=.

# ============================================================================
# AI PROVIDER CONFIGURATION
# ============================================================================

# Wybierz dostawcƒô API (openai, openrouter, ollama)
# - openai: U≈ºywaj bezpo≈õrednio OpenAI API
# - openrouter: Alternatywny dostawca (ta≈Ñszy, wiƒôcej modeli) - REKOMENDOWANY
# - ollama: Lokalne modele bez internetu
AI_PROVIDER=openrouter

# ============================================================================
# API KEY CONFIGURATION
# ============================================================================

# OpenAI API Key
# We≈∫ z https://platform.openai.com/api-keys
# Format: sk-... (zaczyna siƒô od "sk-")
# Koszt: ~$0.003 za prompt (gpt-4o-mini)
# API_KEY=sk-proj-your-api-key-here

# OpenRouter API Key (REKOMENDOWANY - ta≈Ñszy)
# We≈∫ z https://openrouter.ai/keys
# Format: sk-or-v1-... (zaczyna siƒô od "sk-or-v1-")
# Koszt: ~50% taniej ni≈º OpenAI
API_KEY=sk-or-v1-your-api-key-here

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================

# Dla OpenAI:
# - gpt-4o-mini (szybki, tani, rekomendowany)
# - gpt-4o (drogi, mƒÖdrzejszy)
# - gpt-4-turbo (starszy, ale solidny)
MODEL=gpt-4o-mini

# Dla OpenRouter (dostƒôpne modele):
# - meta-llama/llama-2-70b-chat (otwarty, szybki)
# - mistralai/mistral-7b-instruct (szybki, lekki)
# - openai/gpt-4-turbo (drogi, mƒÖdry)
# - anthropic/claude-3-sonnet (niez≈Çy balans)
# MODEL=meta-llama/llama-2-70b-chat

# Dla Ollama (zainstalowane lokalne modele):
# - llama2 (7B, szybki)
# - mistral (7B, bardziej inteligentny)
# - neural-chat (7B, specjalizowany)
# - dolphin-mixtral (lepsza jako≈õƒá)
# MODEL=llama2

# ============================================================================
# OLLAMA CONFIGURATION (tylko dla AI_PROVIDER=ollama)
# ============================================================================

# Lokalna instancja Ollama
# Domy≈õlnie: http://localhost:11434
OLLAMA_BASE_URL=http://localhost:11434

# Je≈õli Ollama na innym hoscie/porcie:
# OLLAMA_BASE_URL=http://192.168.1.100:11434

# ============================================================================
# ADVANCED SETTINGS (Opcjonalne)
# ============================================================================

# Katalog do zapisywania wynik√≥w persistencji
# (domy≈õlnie: results)
PERSISTENCE_DIR=results

# Maksymalny limit token√≥w na request
# (domy≈õlnie: brak limitu, LLM ustala sam)
# MAX_TOKENS=4000

# Temperatura - kreatywno≈õƒá (0.0=deterministyczne, 1.0=tw√≥rcze)
# (domy≈õlnie: 0.7)
# TEMPERATURE=0.7

# ============================================================================
# QUICK START GUIDES
# ============================================================================

# 1. Chcesz szybko testowaƒá - u≈ºywaj OpenRouter + gpt-4o-mini
#    - Ta≈Ñszy: ~$0.0015 za request
#    - Szybki: ~2-3 sekundy na response
#    - Dobrze sprawdzony: tak

# 2. Chcesz offline bez koszt√≥w - u≈ºywaj Ollama
#    a) Zainstaluj: https://ollama.ai
#    b) Uruchom: ollama serve
#    c) Za≈Çaduj model: ollama pull llama2
#    d) W .env ustaw: AI_PROVIDER=ollama, MODEL=llama2

# 3. Chcesz najlepszƒÖ jako≈õƒá - u≈ºywaj OpenAI
#    - Koszt: wy≈ºszy (~$0.005 za request)
#    - Jako≈õƒá: najlepsza
#    - Prƒôdko≈õƒá: ≈õrednia

# ============================================================================
# VERIFICATION
# ============================================================================

# Po ustawieniu .env, sprawd≈∫ czy dzia≈Ça:
#   python -c "from agents import MasterOrchestrator; print('OK')"

# Je≈õli b≈ÇƒÖd, sprawd≈∫:
# 1. API_KEY jest prawid≈Çowy
# 2. AI_PROVIDER jest poprawnie wpisany
# 3. MODEL istnieje dla wybranego dostawcy
# 4. Ollama dzia≈Ça (je≈õli u≈ºywasz ollama)

# ============================================================================
# SECURITY
# ============================================================================

# ‚ö†Ô∏è IMPORTANT: NIE COMMITUJ pliku .env do Gita!
# 1. W .gitignore upewnij siƒô, ≈ºe .env jest wymieniony
# 2. Nigdy nie commituj API keys
# 3. Je≈õli omy≈ÇkƒÖ commitowa≈Çe≈õ klucz - go zresetuj w panelu API

# ============================================================================
