
# ============================================================================
# ü§ñ Multi-Agent Task Decomposition System - Konfiguracja
# ============================================================================

# Wybierz dostawcƒô API
AI_PROVIDER=openrouter

# Klucz API - wstaw sw√≥j tutaj
API_KEY=sk-or-v1-test-demo

# Model do u≈ºycia
MODEL=meta-llama/llama-2-70b-chat

# URL Ollama (je≈õli u≈ºywasz ollama)
OLLAMA_BASE_URL=http://localhost:11434/v1

# ============================================================================
# 1. WYB√ìR DOSTAWCY API
# ============================================================================
# Opcje: openai, openrouter, ollama
# - openai: U≈ºywaj bezpo≈õrednio OpenAI API
# - openrouter: Alternatywny dostawca (ta≈Ñszy, wiƒôcej modeli)
# - ollama: Lokalne modele bez internetu
AI_PROVIDER=openrouter

# ============================================================================
# 2. KLUCZ API (tylko dla OpenAI i OpenRouter)
# ============================================================================

# OpenAI: We≈∫ z https://platform.openai.com/api-keys
# Format: sk-... (zaczyna siƒô od "sk-")
# Koszt: ~$0.003 za prompt (gpt-4o-mini)
# API_KEY=sk-proj-your-api-key-here
API_KEY=sk-proj-your-api-key-here

# OpenRouter (REKOMENDOWANY - ta≈Ñszy):
# We≈∫ z https://openrouter.ai/keys
# Format: sk-or-v1-... (zaczyna siƒô od "sk-or-v1-")
# Koszt: ~50% taniej ni≈º OpenAI
# API_KEY=sk-or-v1-your-api-key-here

# ============================================================================
# 3. WYB√ìR MODELU
# ============================================================================

# Dla OpenAI:
# - gpt-4o-mini (szybki, tani, rekomendowany)
# - gpt-4o (drogi, mƒÖdrzejszy)
# - gpt-4-turbo (starszy, ale solidny)
MODEL=gpt-4o-mini

# Dla OpenRouter (dostƒôpne modele):
# - meta-llama/llama-2-70b-chat (otwarty, szybki)
# - mistralai/mistral-7b-instruct (szybki, lekki)
# - openai/gpt-4-turbo (drogi, mƒÖdry)
# - anthropic/claude-3-sonnet (niez≈Çy balans)
# MODEL=meta-llama/llama-2-70b-chat

# Dla Ollama (zainstalowane lokalne modele):
# - llama2 (7B, szybki)
# - mistral (7B, bardziej inteligentny)
# - neural-chat (7B, specjalizowany)
# - dolphin-mixtral (lepsza jako≈õƒá)
# MODEL=llama2

# ============================================================================
# 4. KONFIGURACJA OLLAMA (tylko dla AI_PROVIDER=ollama)
# ============================================================================

# Lokalna instancja Ollama
# Domy≈õlnie: http://localhost:11434/v1
OLLAMA_BASE_URL=http://localhost:11434

# Je≈õli Ollama na innym hoscie/porcie:
# OLLAMA_BASE_URL=http://192.168.1.100:11434

# ============================================================================
# 5. OPCJONALNE: USTAWIENIA ZAAWANSOWANE
# ============================================================================

# Domy≈õlny katalog workspace dla edytora plik√≥w
# (domy≈õlnie: katalog g≈Ç√≥wny projektu)
# WORKSPACE_DIR=/home/user/my-project
# WORKSPACE_DIR=.

# Katalog do zapisywania wynik√≥w persistencji
# (domy≈õlnie: results)
PERSISTENCE_DIR=results

# Maksymalny limit token√≥w na request
# (domy≈õlnie: brak limitu, LLM ustala sam)
# MAX_TOKENS=4000

# Temperatura - kreatywno≈õƒá (0.0=deterministyczne, 1.0=tw√≥rcze)
# (domy≈õlnie: 0.7)
# TEMPERATURE=0.7

# ============================================================================
# SZYBKIE PRZEWODNIKI
# ============================================================================

# 1. Chcesz szybko testowaƒá - u≈ºywaj OpenRouter + gpt-4o-mini
#    - Ta≈Ñszy: ~$0.0015 za request
#    - Szybki: ~2-3 sekundy na response
#    - Dobrze sprawdzony: tak

# 2. Chcesz offline bez koszt√≥w - u≈ºywaj Ollama
#    a) Zainstaluj: https://ollama.ai
#    b) Uruchom: ollama serve
#    c) Za≈Çaduj model: ollama pull llama2
#    d) W .env ustaw: AI_PROVIDER=ollama, MODEL=llama2

# 3. Chcesz najlepszƒÖ jako≈õƒá - u≈ºywaj OpenAI
#    - Koszt: wy≈ºszy (~$0.005 za request)
#    - Jako≈õƒá: najlepsza
#    - Prƒôdko≈õƒá: ≈õrednia

# ============================================================================
# SPRAWDZENIE KONFIGURACJI
# ============================================================================

# Po ustawieniu .env, sprawd≈∫ czy dzia≈Ça:
#   python -c "from agents import MasterOrchestrator; print('OK')"

# Je≈õli b≈ÇƒÖd, sprawd≈∫:
# 1. API_KEY jest prawid≈Çowy
# 2. AI_PROVIDER jest poprawnie wpisany
# 3. MODEL istnieje dla wybranego dostawcy
# 4. Ollama dzia≈Ça (je≈õli u≈ºywasz ollama)

# ============================================================================
# BEZPIECZE≈ÉSTWO
# ============================================================================

# NIE COMMITUJ tego pliku do Gita!
# 1. W .gitignore upewnij siƒô, ≈ºe .env jest wymieniony
# 2. Nigdy nie commituj API keys
# 3. Je≈õli omy≈ÇkƒÖ commitowa≈Çe≈õ klucz - go zresetuj w panelu API

# ============================================================================
