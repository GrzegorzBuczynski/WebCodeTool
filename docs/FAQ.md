# â“ FAQ - NajczÄ™Å›ciej Zadawane Pytania

## ğŸ”§ Instalacja & Konfiguracja

### P: Co potrzebujÄ™ do uruchomienia tego systemu?
**O:** Tylko:
- Python 3.8+
- API key (OpenAI, OpenRouter) LUB lokalnie: Ollama
- ~100MB place na dysku

### P: Czy mogÄ™ uruchomiÄ‡ bez internetu?
**O:** Tak! UÅ¼yj Ollama:
```bash
# Zainstaluj: https://ollama.ai
ollama pull llama2
ollama serve

# W .env:
AI_PROVIDER=ollama
MODEL=llama2
```

### P: Jaki dostawca wybraÄ‡?
**O:** To zaleÅ¼y:
- **OpenRouter** - Najlepszy wybÃ³r dla poczÄ…tkujÄ…cych (taÅ„szy)
- **OpenAI** - Najlepsza jakoÅ›Ä‡, droÅ¼szy
- **Ollama** - Darmowy, ale wymaga zainstalowania

### P: Ile bÄ™dzie mnie to kosztowaÄ‡?
**O:** ZaleÅ¼y od dostawcy:
- **OpenRouter**: ~$0.0015 za request
- **OpenAI (gpt-4o-mini)**: ~$0.003 za request
- **Ollama**: $0 (lokalnie)

10 requestÃ³w = $0.015 - $0.03

### P: Czy API key jest bezpieczny?
**O:** Zalecenia:
1. âœ… Przechowuj w `.env` (w `.gitignore`)
2. âŒ NIGDY nie commituj `.env`
3. âœ… JeÅ›li wycieknÄ…Å‚ - zresetuj w panelu API
4. âœ… Monitoruj uÅ¼ycie w panelu dostawcy

---

## ğŸ¤– Jak dziaÅ‚a system?

### P: Co robi ComplexityAnalyzer?
**O:** Analizuje czy zadanie powinno byÄ‡ podzielone:

```
ZÅ‚oÅ¼onoÅ›Ä‡: NISKA/ÅšREDNIA/WYSOKA/BARDZO_WYSOKA
Output: <500/<1500/<5000/>5000 sÅ‚Ã³w

NISKA + KRÃ“TKI â†’ Wykonaj bezpoÅ›rednio
WYSOKA + BARDZO_DÅUGI â†’ Podziel na 4-5 podtaskÃ³w
```

### P: Ile maksymalnie poziomÃ³w rekursji?
**O:** System poddziaÅ‚ maksymalnie na 10 poziomÃ³w (safety limit), ale zazwyczaj 1-3 wystarczajÄ….

### P: Czy 5 ExecutorAgentÃ³w to minimum?
**O:** Nie, to domyÅ›lnie. MoÅ¼esz zmieniÄ‡:
```python
MasterOrchestrator(num_executors=10)
```

### P: Co robi VerificationAgent?
**O:** Sprawdza kaÅ¼de zadanie i daje mu ocenÄ™ 0-10 + feedback.

### P: Czy mogÄ™ zobaczyÄ‡ hierarchiÄ™ zadaÅ„?
**O:** Tak:
```python
orchestrator.print_statistics()  # Podsumowanie
```

i w `results/task_results/task_XXXX_hierarchy.json`

---

## ğŸ’¾ Persistencja & Wyniki

### P: Gdzie sÄ… zapisane wyniki?
**O:** W katalogu `results/`:
- `task_results/` - Wyniki zadaÅ„
- `statistics/` - Statystyki
- `execution_logs/` - Logi

### P: MogÄ™ zmieniÄ‡ folder na wyniki?
**O:** Tak:
```python
orchestrator = MasterOrchestrator(
    persistence_dir="/moja/sciezka"
)
```

### P: Co jeÅ›li brakuje `results/`?
**O:** System tworzy automatycznie. JeÅ›li nie - problem z uprawnieniami:
```bash
mkdir -p results/{task_results,statistics,execution_logs}
chmod 755 results
```

### P: Czy mogÄ™ wyeksportowaÄ‡ wyniki do CSV?
**O:** Na razie JSON i TXT. CSV planuje siÄ™ w v3.0.

### P: Jak duÅ¼e mogÄ… byÄ‡ wyniki?
**O:** ZaleÅ¼y od liczby zadaÅ„:
- Proste: ~10 KB
- Åšrednie: ~100 KB
- DuÅ¼e: ~1-10 MB

### P: Czy starego wyniki siÄ™ usuwajÄ…?
**O:** Nie, pozostajÄ…. JeÅ›li chcesz wyczyÅ›ciÄ‡:
```bash
rm -rf results/
```

---

## ğŸŒ API & Modele

### P: Jakie modele obsÅ‚ugujesz?
**O:** Teoretycznie kaÅ¼dy przez OpenAI SDK:
- OpenAI: gpt-4, gpt-4o-mini, gpt-3.5-turbo
- OpenRouter: 100+ modeli
- Ollama: llama2, mistral, neural-chat, itp.

### P: Czy mogÄ™ przeÅ‚Ä…czaÄ‡ modele mid-execution?
**O:** Nie, musiaÅ‚byÅ› zrestartowaÄ‡. ZmieÅ„ w `.env`.

### P: OpenRouter - czy sÄ… jakieÅ› limity?
**O:** Tak:
- Free tier: ograniczone RPM
- PÅ‚atny: $5/miesiÄ…c lub "pay as you go"

### P: Czy wspierasz Claude/GPT-4?
**O:** Tak, przez OpenRouter:
- Claude: `anthropic/claude-3-sonnet`
- GPT-4: `openai/gpt-4`

---

## ğŸ› Problemy & RozwiÄ…zania

### P: "ModuleNotFoundError: No module named 'openai'"
**O:**
```bash
pip install openai>=1.12.0
# LUB
pip install -r requirements.txt
```

### P: "BÅ‚Ä…d poÅ‚Ä…czenia z API"
**O:** SprawdÅº:
1. Klucz API w `.env` jest prawidÅ‚owy
2. Internet dziaÅ‚a
3. Limit requestÃ³w nie wyczerpany

### P: "Ollama connection refused"
**O:**
```bash
# Terminal 1:
ollama serve

# Terminal 2:
python main.py
```

### P: "Task output is BARDZO_DÅUGI but not decomposing"
**O:** Bug? SprawdÅº czy:
1. ComplexityAnalyzer ma dostÄ™p do LLM
2. Model "rozumie" instrukcje (nie wszystkie)

### P: Zadanie trwa zbyt dÅ‚ugo
**O:** Zmniejsz gÅ‚Ä™bokoÅ›Ä‡ lub liczba podtaskÃ³w:
```python
# W main.py:
max_recursion_depth=5  # Zamiast 10
```

### P: BÅ‚Ä™dy w JSON w results/
**O:** SprawdÅº uprawnienia zapisu:
```bash
chmod -R 755 results/
```

---

## ğŸ“Š Optymalizacja

### P: Jak mogÄ™ przyÅ›pieszyÄ‡ wykonanie?
**O:**
1. UÅ¼yj szybszego modelu (llama zamiast gpt-4)
2. OpenRouter zamiast OpenAI
3. Zmniejsz num_executors lub max_recursion_depth

### P: Ile czasu zajmuje jedno zadanie?
**O:** ZaleÅ¼y:
- Proste (NISKA): 10-20 sekund
- Åšrednie (ÅšREDNIA): 30-60 sekund
- DuÅ¼e (WYSOKA): 1-3 minuty

### P: Czy mogÄ™ paralelizowaÄ‡ Executor Agents?
**O:** Nie, to "pseudo-parallel" (round-robin). Rzeczywista paralelizacja w v3.0.

### P: Czy mogÄ™ cachowaÄ‡ wyniki?
**O:** Na razie nie, ale planuje siÄ™ w v3.0.

---

## ğŸ’¡ Zaawansowane

### P: Czy mogÄ™ edytowaÄ‡ agentÃ³w?
**O:** OczywiÅ›cie! W `agents.py` zmieÅ„ prompty czy logikÄ™.

### P: Jak dodaÄ‡ nowego agenta?
**O:** 
```python
class MojAgent(BaseAgent):
    def analyze(self, task: str) -> str:
        prompt = f"ZrÃ³b coÅ› z: {task}"
        return self.call_llm(prompt)
```

### P: Czy mogÄ™ uÅ¼yÄ‡ tego w produkcji?
**O:** OstroÅ¼nie:
- Wersja 2.0.0 - Production Ready
- Ale pamiÄ™taj o kosztach API!
- Dodaj monitoring i logowanie

### P: Czy wspierasz mÃºltijÄ™zycznoÅ›Ä‡?
**O:** Tak, system zawsze uÅ¼ywa jÄ™zyka wejÅ›cia (PL w tym przypadku).

### P: Czy mogÄ™ integrowaÄ‡ z Django/Flask?
**O:** Tak:
```python
from agents import MasterOrchestrator

def my_view(request):
    task = request.GET.get('task')
    orchestrator = MasterOrchestrator()
    result = orchestrator.process_task_recursive(task)
    return JsonResponse(result)
```

### P: Czy jest REST API?
**O:** Na razie nie, ale planuje siÄ™ w v3.0.

---

## ğŸ“š Zasoby & Nauka

### P: Gdzie mogÄ™ dowiedzieÄ‡ siÄ™ wiÄ™cej o multi-agent systems?
**O:** 
- Paper: "Multi-Agent Systems: A Modern Approach" (Wooldridge)
- Video: LangChain docs na YouTube
- GitHub: microsoft/autogen

### P: Czy system wspiera LangChain?
**O:** Nie, ale je moÅ¼na integrowaÄ‡.

### P: Czy mogÄ™ dodaÄ‡ wÅ‚asne narzÄ™dzia (tools)?
**O:** Tak, w `BaseAgent.call_llm()` moÅ¼na dodaÄ‡ function calling.

### P: Jak wdroÅ¼yÄ‡ do produkcji?
**O:** Best practices:
1. Containerize (Docker)
2. Dodaj monitoring (Sentry/Datadog)
3. Setup rate limiting
4. Backup results
5. Monitoring cost

---

## ğŸ¯ NajczÄ™stsze Use Cases

### 1. Analiza duÅ¼ych dokumentÃ³w
```
"Przeanalizuj raport i wyciÄ…gnij kluczowe punkty"
```
â†’ System podzieli na sekcje

### 2. Tworzenie zawartoÅ›ci
```
"Napisz 5000-sÅ‚owy artykuÅ‚ o AI"
```
â†’ Podzielone na rozdziaÅ‚y, kaÅ¼dy napisany osobno

### 3. RozwiÄ…zywanie problemÃ³w
```
"Jak zbudowniÄ‡ startup? Od pomysÅ‚u do IPO"
```
â†’ Podzielone na fazy (ideacja, MVP, funding, itp.)

### 4. Testowanie
```
"Testuj mÃ³j kod na edge cases"
```
â†’ RÃ³Å¼ne agenty testujÄ… rÃ³Å¼ne scenariusze

---

## ğŸš€ Tips & Tricks

### 1. Szybkie testowanie
```bash
python quick_test.py
# Zamiast czekaÄ‡ na full workflow
```

### 2. Debug mode
Edytuj `agents.py` i zmieÅ„ print() na:
```python
print(f"[DEBUG] {message}")
# Plus log to file
```

### 3. Monitoring kosztÃ³w OpenRouter
```bash
# Sprawdzaj w panelu: https://openrouter.ai/account/usage
```

### 4. Custom models
```python
# W .env
MODEL=meta-llama/llama-2-70b-chat:free
# :free = darmowy tier (jeÅ›li dostÄ™pny)
```

---

## ğŸ“ Jak uzyskaÄ‡ pomoc?

1. **SprawdzÄ™ dokumentacjÄ™**: 
   - [README_COMPLETE.md](README_COMPLETE.md)
   - [PERSISTENCE.md](PERSISTENCE.md)

2. **Szukaj w FAQ** (ten plik)

3. **Testuj funkcje**: `python test_*.py`

4. **SprawdÅº logi**: `results/execution_logs/`

5. **Modyfikuj kod**: Wszystko jest open source

---

**Ostatnia aktualizacja**: 2024-12-07  
**Wersja**: 2.0.0

Masz pytanie ktÃ³re nie jest tu? Dodaj je! ğŸ“
